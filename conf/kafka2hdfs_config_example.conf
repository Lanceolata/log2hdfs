[global]
log.path = test.log
log.size = 2048

[hdfs]
namenode = hdfs://hadoopcluster
port = 8020
user = data-infra

[kakfa]
client.id = kafka2hdfs0
internal.termination.signal = 29
group.id = log2hdfs_kafka2hdfs
enable.auto.commit = true
auto.commit.interval.ms = 5000
enable.auto.offset.store = true
queued.min.messages = 12000
offset.store.method = file

# old kafka
#metadata.broker.list = 192.168.145.201:9092,192.168.145.202:9092,192.168.145.203:9092,192.168.145.204:9092,192.168.145.205:9092,192.168.145.206:9092,192.168.145.207:9092,192.168.145.208:9092,192.168.145.209:9092,192.168.145.210:9092
#broker.version.fallback = 0.8.2

# new kafka
metadata.broker.list = 192.168.145.216:9092,192.168.145.217:9092,192.168.145.218:9092,192.168.145.221:9092,192.168.145.222:9092,192.168.145.223:9092,192.168.145.224:9092,192.168.145.225:9092,192.168.145.226:9092,192.168.145.227:9092
api.version.request = true

[click]
kafka.offset = KAFKA_OFFSET_STORED
kafka.enable.auto.commit = true
kafka.auto.commit.interval.ms = 5000
kafka.auto.offset.reset = largest
kafka.offset.store.method = file
kafka.offset.store.path = /data/users/data-infra/kafka2hdfs/offset


[impression]
