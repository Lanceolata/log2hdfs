# librdkafka configure
[kafka]
client.id = log2kafka
message.max.bytes = 100000
max.in.flight.requests.per.connection = 10
queue.buffering.max.messages = 100000
queue.buffering.max.kbytes = 400000
queue.buffering.max.ms = 1000
message.send.max.retries = 3
retry.backoff.ms = 3000
batch.num.messages = 10000

# old kafka
#metadata.broker.list = 192.168.145.201:9092,192.168.145.202:9092,192.168.145.203:9092,192.168.145.204:9092,192.168.145.205:9092,192.168.145.206:9092,192.168.145.207:9092,192.168.145.208:9092,192.168.145.209:9092,192.168.145.210:9092
#broker.version.fallback = 0.8.2

# new kafka
metadata.broker.list = 192.168.145.216:9092,192.168.145.217:9092,192.168.145.218:9092,192.168.145.221:9092,192.168.145.222:9092,192.168.145.223:9092,192.168.145.224:9092,192.168.145.225:9092,192.168.145.226:9092,192.168.145.227:9092

# global configure
[global]
# only in global
handle.dir = remedy
handle.interval = 1800
handle.remedy = true
table.path = offset_table
table.interval = 30

# default configure
[default]
# kafka
kafka.message.timeout.ms = 30000
#kafka.compression.codec = snappy

remedy = -1

# log2kafka produce
batch.num = 200
poll.timeout = 300
poll.messages = 2000

# topic configure
[bid]
dirs = /data/ef-logs/bid
remedy = 180
