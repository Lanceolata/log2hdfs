# hdfs configuration
[hdfs]
type = command
namenode = hdfs://hadoopcluster
port = 8020
user = data-infra
put = hadoop fs -put
append = hadoop fs -appendToFile
lzo.index = hadoop jar /usr/lib/hadoop/lib/hadoop-lzo-0.4.19.jar com.hadoop.compression.lzo.LzoIndexer

# librdkafka configuration
[kafka]
client.id = kafka2hdfs-ef
group.id = kafka2hdfs
enable.auto.commit = true
auto.commit.interval.ms = 5000
enable.auto.offset.store = true
queued.min.messages = 20000
offset.store.method = file

# old kafka
metadata.broker.list = 192.168.145.201:9092,192.168.145.202:9092,192.168.145.203:9092,192.168.145.204:9092,192.168.145.205:9092,192.168.145.206:9092,192.168.145.207:9092,192.168.145.208:9092,192.168.145.209:9092,192.168.145.210:9092
broker.version.fallback = 0.8.2

# new kafka
#metadata.broker.list = 192.168.145.216:9092,192.168.145.217:9092,192.168.145.218:9092,192.168.145.221:9092,192.168.145.222:9092,192.168.145.223:9092,192.168.145.224:9092,192.168.145.225:9092,192.168.145.226:9092,192.168.145.227:9092

[default]
# kafka
kafka.enable.auto.commit = true
kafka.auto.commit.interval.ms = 5000
#kafka.auto.offset.reset = smallest
kafka.offset.store.method = file
kafka.offset.store.path = ef-offset

root.dir = ef-k2h
log.format = ef
path.format = normal
consume.type = ef
upload.type = text
parallel = 3
compress.lzo = /usr/local/bin/lzop -1 -U -f --ignore-warn
compress.orc = 
compress.mv = 

consume.interval = 3600
complete.interval = 600
complete.maxsize = 0
retention.seconds = 3600
upload.interval = 20

[adv]
partitions = 0-9
offsets = -1000
consume.interval = 900
complete.interval = 1800
complete.maxsize = 104857600
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[cvt]
partitions = 0-4
offsets = -1000
consume.interval = 900
complete.interval = 1800
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[ic]
partitions = 0-9
offsets = -1000
consume.interval = 900
log.format = efic
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%k_%Y%m%d%H%M.seq

[rc]
partitions = 0-4
offsets = -1000
consume.interval = 1200
hdfs.path = /user/root/flume/rc/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[stats]
partitions = 0-9
offsets = -1000
consume.interval = 900
log.format = efstats
hdfs.path = /user/root/flume/3th_stats/%p/%Y/%m/%d/%H/%A_%Y%m%d%H%M.seq

[pub]
partitions = 0-4
offsets = -1000
consume.interval = 1200
log.format = pub
hdfs.path = /user/root/flume/log_access/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

# aws

[bid_aws]
partitions = 0-3
offsets = -1000
log.format = efdevice
hdfs.path = /user/root/flume/express_bid/%Y/%m/%d/%H/%t_%Y%m%d%H%M_%D.seq

[unbid_aws]
partitions = 0-7
offsets = -1000
log.format = efdevice
hdfs.path = /user/root/flume/express_bid/%Y/%m/%d/%H/%t_%Y%m%d%H%M_%D.seq

[adv_aws]
partitions = 0-1
offsets = -1000
consume.interval = 1800
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[cvt_aws]
partitions = 0-1
offsets = -1000
consume.interval = 1800
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[ic_aws]
partitions = 0-3
offsets = -1000
consume.interval = 1800
log.format = eficaws
hdfs.path = /user/root/flume/express/%Y/%m/%d/%H/%A_aws_%D_%Y%m%d%H%M.seq

# selfmedia

[imp]
partitions = 0-10
offsets = -1000
consume.interval = 900
log.format = efimp
hdfs.path = /user/root/flume/selfmedia/%A/%Y/%m/%d/%H/%A_%Y%m%d%H%M.seq

[failsafe]
partitions = 0-1
offsets = -1000
hdfs.path = /user/root/flume/selfmedia/failsafe/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[pdb-bid]
partitions = 0-9
offsets = -1000
consume.interval = 1200
hdfs.path = /user/root/flume/selfmedia/pdb-bid/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[pdb-unbid]
partitions = 0-4
offsets = -1000
consume.interval = 1200
hdfs.path = /user/root/flume/selfmedia/pdb-unbid/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[unimp]
partitions = 0-4
offsets = -1000
consume.interval = 900
hdfs.path = /user/root/flume/selfmedia/imp/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

# pydmp

[pydmpadv]
partitions = 0-3
offsets = -1000
consume.interval = 1800
hdfs.path = /user/data-infra/pydmp/adv/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[pydmpclick]
partitions = 0-2
offsets = -1000
consume.interval = 1800
hdfs.path = /user/data-infra/pydmp/click/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[pydmpcvt]
partitions = 0-1
offsets = -1000
consume.interval = 1800
hdfs.path = /user/data-infra/pydmp/cvt/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[pydmpimp]
partitions = 0-3
offsets = -1000
consume.interval = 1200
hdfs.path = /user/data-infra/pydmp/imp/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

[cm_reachmax]
partitions = 0-4
offsets = -1000
consume.interval = 1200
hdfs.path = /user/data-infra/cm_reachmax/%Y/%m/%d/%H/%t_%Y%m%d%H%M.seq

